{
  "sympy__sympy-16792__claude-3.7": {
    "model_patch": "diff --git a/sympy/utilities/codegen.py b/sympy/utilities/codegen.py\nindex f0befb2bd7..c363758133 100644\n--- a/sympy/utilities/codegen.py\n+++ b/sympy/utilities/codegen.py\n@@ -910,7 +910,7 @@ def get_prototype(self, routine):\n         type_args = []\n         for arg in routine.arguments:\n             name = self.printer.doprint(arg.name)\n-            if arg.dimensions or isinstance(arg, ResultBase):\n+            if arg.dimensions or isinstance(arg, ResultBase) or isinstance(arg.name, MatrixSymbol):\n                 type_args.append((arg.get_datatype('C'), \"*%s\" % name))\n             else:\n                 type_args.append((arg.get_datatype('C'), name))\ndiff --git a/sympy/utilities/tests/test_codegen.py b/sympy/utilities/tests/test_codegen.py\nindex 1cd56e12d1..78e2c4db36 100644\n--- a/sympy/utilities/tests/test_codegen.py\n+++ b/sympy/utilities/tests/test_codegen.py\n@@ -582,6 +582,25 @@ def test_ccode_cse():\n     )\n     assert source == expected\n \n+def test_ccode_unused_array_arg():\n+    x = MatrixSymbol('x', 2, 1)\n+    # x does not appear in output\n+    name_expr = (\"test\", 1.0)\n+    generator = CCodeGen()\n+    result = codegen(name_expr, code_gen=generator, header=False, empty=False, argument_sequence=(x,))\n+    source = result[0][1]\n+    # note: x should appear as (double *)\n+    expected = (\n+        '#include \"test.h\"\\n'\n+        '#include <math.h>\\n'\n+        'double test(double *x) {\\n'\n+        '   double test_result;\\n'\n+        '   test_result = 1.0;\\n'\n+        '   return test_result;\\n'\n+        '}\\n'\n+    )\n+    assert source == expected\n+\n def test_empty_f_code():\n     code_gen = FCodeGen()\n     source = get_string(code_gen.dump_f95, [])\n",
    "model_name_or_path": "claude-3.7"
  },
  "sympy__sympy-16792__deepseek-chat": {
    "model_patch": "diff --git a/sympy/utilities/codegen.py b/sympy/utilities/codegen.py\nindex f0befb2bd7..c363758133 100644\n--- a/sympy/utilities/codegen.py\n+++ b/sympy/utilities/codegen.py\n@@ -910,7 +910,7 @@ def get_prototype(self, routine):\n         type_args = []\n         for arg in routine.arguments:\n             name = self.printer.doprint(arg.name)\n-            if arg.dimensions or isinstance(arg, ResultBase):\n+            if arg.dimensions or isinstance(arg, ResultBase) or isinstance(arg.name, MatrixSymbol):\n                 type_args.append((arg.get_datatype('C'), \"*%s\" % name))\n             else:\n                 type_args.append((arg.get_datatype('C'), name))\n",
    "model_name_or_path": "deepseek-chat"
  },
  "psf__requests-2674__claude-3.7": {
    "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex 841cbbfe..b8077868 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -27,6 +27,9 @@ from .packages.urllib3.exceptions import ProtocolError\n from .packages.urllib3.exceptions import ReadTimeoutError\n from .packages.urllib3.exceptions import SSLError as _SSLError\n from .packages.urllib3.exceptions import ResponseError\n+from .packages.urllib3.exceptions import ClosedPoolError\n+from .packages.urllib3.exceptions import DecodeError\n+from .packages.urllib3.exceptions import TimeoutError\n from .cookies import extract_cookies_to_jar\n from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n                          ProxyError, RetryError)\n@@ -409,7 +412,7 @@ class HTTPAdapter(BaseAdapter):\n                     low_conn.close()\n                     raise\n \n-        except (ProtocolError, socket.error) as err:\n+        except (ProtocolError, socket.error, ClosedPoolError, DecodeError, TimeoutError) as err:\n             raise ConnectionError(err, request=request)\n \n         except MaxRetryError as e:\n",
    "model_name_or_path": "claude-3.7"
  },
  "psf__requests-2674__deepseek-chat": {
    "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex 841cbbfe..4286f7bc 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -27,6 +27,8 @@ from .packages.urllib3.exceptions import ProtocolError\n from .packages.urllib3.exceptions import ReadTimeoutError\n from .packages.urllib3.exceptions import SSLError as _SSLError\n from .packages.urllib3.exceptions import ResponseError\n+from .packages.urllib3.exceptions import DecodeError as _DecodeError\n+from .packages.urllib3.exceptions import TimeoutError as _TimeoutError\n from .cookies import extract_cookies_to_jar\n from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n                          ProxyError, RetryError)\n@@ -431,5 +433,9 @@ class HTTPAdapter(BaseAdapter):\n                 raise ReadTimeout(e, request=request)\n             else:\n                 raise\n+        except _DecodeError as e:\n+            raise DecodeError(e, request=request)\n+        except _TimeoutError as e:\n+            raise Timeout(e, request=request)\n \n         return self.build_response(request, resp)\n",
    "model_name_or_path": "deepseek-chat"
  },
  "pallets__flask-5063__claude-3.7": {
    "model_patch": "diff --git a/src/flask/cli.py b/src/flask/cli.py\nindex 37a15ff2..76360e20 100644\n--- a/src/flask/cli.py\n+++ b/src/flask/cli.py\n@@ -1018,20 +1018,56 @@ def routes_command(sort: str, all_methods: bool) -> None:\n         for rule in rules\n     ]\n \n-    headers = (\"Endpoint\", \"Methods\", \"Rule\")\n-    widths = (\n-        max(len(rule.endpoint) for rule in rules),\n-        max(len(methods) for methods in rule_methods),\n-        max(len(rule.rule) for rule in rules),\n-    )\n+    # Check if any rules have a subdomain or host\n+    has_subdomain = any(rule.subdomain is not None for rule in rules)\n+    has_host = current_app.url_map.host_matching\n+\n+    if has_subdomain:\n+        headers = (\"Subdomain\", \"Endpoint\", \"Methods\", \"Rule\")\n+    elif has_host:\n+        headers = (\"Host\", \"Endpoint\", \"Methods\", \"Rule\")\n+    else:\n+        headers = (\"Endpoint\", \"Methods\", \"Rule\")\n+\n+    if has_subdomain:\n+        widths = (\n+            max(len(rule.subdomain or \"\") for rule in rules),\n+            max(len(rule.endpoint) for rule in rules),\n+            max(len(methods) for methods in rule_methods),\n+            max(len(rule.rule) for rule in rules),\n+        )\n+    elif has_host:\n+        widths = (\n+            max(len(rule.host or \"\") for rule in rules),\n+            max(len(rule.endpoint) for rule in rules),\n+            max(len(methods) for methods in rule_methods),\n+            max(len(rule.rule) for rule in rules),\n+        )\n+    else:\n+        widths = (\n+            max(len(rule.endpoint) for rule in rules),\n+            max(len(methods) for methods in rule_methods),\n+            max(len(rule.rule) for rule in rules),\n+        )\n     widths = [max(len(h), w) for h, w in zip(headers, widths)]\n-    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}\".format(*widths)\n+    \n+    if has_subdomain:\n+        row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}  {{3:<{3}}}\".format(*widths)\n+    elif has_host:\n+        row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}  {{3:<{3}}}\".format(*widths)\n+    else:\n+        row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}\".format(*widths)\n \n     click.echo(row.format(*headers).strip())\n     click.echo(row.format(*(\"-\" * width for width in widths)))\n \n     for rule, methods in zip(rules, rule_methods):\n-        click.echo(row.format(rule.endpoint, methods, rule.rule).rstrip())\n+        if has_subdomain:\n+            click.echo(row.format(rule.subdomain or \"\", rule.endpoint, methods, rule.rule).rstrip())\n+        elif has_host:\n+            click.echo(row.format(rule.host or \"\", rule.endpoint, methods, rule.rule).rstrip())\n+        else:\n+            click.echo(row.format(rule.endpoint, methods, rule.rule).rstrip())\n \n \n cli = FlaskGroup(\n",
    "model_name_or_path": "claude-3.7"
  },
  "pallets__flask-5063__deepseek-chat": {
    "model_patch": "diff --git a/src/flask/cli.py b/src/flask/cli.py\nindex 37a15ff2..9543e3b7 100644\n--- a/src/flask/cli.py\n+++ b/src/flask/cli.py\n@@ -1018,20 +1018,30 @@ def routes_command(sort: str, all_methods: bool) -> None:\n         for rule in rules\n     ]\n \n-    headers = (\"Endpoint\", \"Methods\", \"Rule\")\n+    # Get server name for domain formatting\n+    server_name = current_app.config.get(\"SERVER_NAME\", \"localhost\")\n+    if \":\" in server_name:\n+        server_name = server_name.split(\":\", 1)[0]\n+\n+    headers = (\"Domain\", \"Endpoint\", \"Methods\", \"Rule\")\n     widths = (\n+        max(len(server_name) + len(rule.subdomain or \"\") + 1 for rule in rules),\n         max(len(rule.endpoint) for rule in rules),\n         max(len(methods) for methods in rule_methods),\n         max(len(rule.rule) for rule in rules),\n     )\n     widths = [max(len(h), w) for h, w in zip(headers, widths)]\n-    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}\".format(*widths)\n+    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}  {{3:<{3}}}\".format(*widths)\n \n     click.echo(row.format(*headers).strip())\n     click.echo(row.format(*(\"-\" * width for width in widths)))\n \n     for rule, methods in zip(rules, rule_methods):\n-        click.echo(row.format(rule.endpoint, methods, rule.rule).rstrip())\n+        if rule.subdomain:\n+            domain = f\"{rule.subdomain}.{server_name}\"\n+        else:\n+            domain = server_name\n+        click.echo(row.format(domain, rule.endpoint, methods, rule.rule).rstrip())\n \n \n cli = FlaskGroup(\ndiff --git a/tests/test_cli.py b/tests/test_cli.py\nindex 0d9625b1..a9183ec4 100644\n--- a/tests/test_cli.py\n+++ b/tests/test_cli.py\n@@ -472,6 +472,24 @@ class TestRoutes:\n         assert result.exit_code == 0\n         self.expect_order([\"aaa_post\", \"static\", \"yyy_get_post\"], result.output)\n \n+    def test_subdomain(self, runner):\n+        app = Flask(__name__, static_folder=None)\n+        app.add_url_rule(\"/a\", subdomain=\"a\", endpoint=\"a\")\n+        app.add_url_rule(\"/b\", subdomain=\"b\", endpoint=\"b\")\n+        cli = FlaskGroup(create_app=lambda: app)\n+        result = runner.invoke(cli, [\"routes\"])\n+        assert result.exit_code == 0\n+        assert \"Subdomain\" in result.output\n+\n+    def test_host(self, runner):\n+        app = Flask(__name__, static_folder=None, host_matching=True)\n+        app.add_url_rule(\"/a\", host=\"a\", endpoint=\"a\")\n+        app.add_url_rule(\"/b\", host=\"b\", endpoint=\"b\")\n+        cli = FlaskGroup(create_app=lambda: app)\n+        result = runner.invoke(cli, [\"routes\"])\n+        assert result.exit_code == 0\n+        assert \"Host\" in result.output\n+\n     def test_sort(self, app, invoke):\n         default_output = invoke([\"routes\"]).output\n         endpoint_output = invoke([\"routes\", \"-s\", \"endpoint\"]).output\n",
    "model_name_or_path": "deepseek-chat"
  },
  "django__django-14382__deepseek-chat": {
    "model_patch": "diff --git a/django/core/management/templates.py b/django/core/management/templates.py\nindex 8dc6068286..f248ab1b71 100644\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -74,7 +74,7 @@ class TemplateCommand(BaseCommand):\n                 raise CommandError(e)\n         else:\n             if app_or_project == 'app':\n-                self.validate_name(os.path.basename(target), 'directory')\n+                self.validate_name(os.path.basename(target.rstrip(os.sep)), 'directory')\n             top_dir = os.path.abspath(os.path.expanduser(target))\n             if not os.path.exists(top_dir):\n                 raise CommandError(\"Destination directory '%s' does not \"\n",
    "model_name_or_path": "deepseek-chat"
  },
  "django__django-14382__claude-3.7": {
    "model_patch": "diff --git a/django/core/management/templates.py b/django/core/management/templates.py\nindex 8dc60682868..f248ab1b71a 100644\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -74,7 +74,7 @@ class TemplateCommand(BaseCommand):\n                 raise CommandError(e)\n         else:\n             if app_or_project == 'app':\n-                self.validate_name(os.path.basename(target), 'directory')\n+                self.validate_name(os.path.basename(target.rstrip(os.sep)), 'directory')\n             top_dir = os.path.abspath(os.path.expanduser(target))\n             if not os.path.exists(top_dir):\n                 raise CommandError(\"Destination directory '%s' does not \"\n",
    "model_name_or_path": "claude-3.7"
  },
  "pydicom__pydicom-1256__deepseek-chat": {
    "model_patch": "diff --git a/pydicom/jsonrep.py b/pydicom/jsonrep.py\nindex c6ef519c3..697bba8b0 100644\n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -224,9 +224,10 @@ class JsonDataElementConverter:\n                         VR=vr)\n                 else:\n                     value_key = unique_value_keys[0]\n-                    elem = DataElement.from_json(\n+                elem = DataElement.from_json(\n                         self.dataset_class, key, vr,\n-                        val[value_key], value_key\n+                        val[value_key], value_key,\n+                        self.bulk_data_element_handler\n                     )\n                 ds.add(elem)\n         return ds\n",
    "model_name_or_path": "deepseek-chat"
  },
  "pydicom__pydicom-1256__claude-3.7": {
    "model_patch": "diff --git a/pydicom/jsonrep.py b/pydicom/jsonrep.py\nindex c6ef519c3..52bf00ce0 100644\n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -226,7 +226,8 @@ class JsonDataElementConverter:\n                     value_key = unique_value_keys[0]\n                     elem = DataElement.from_json(\n                         self.dataset_class, key, vr,\n-                        val[value_key], value_key\n+                        val[value_key], value_key,\n+                        self.bulk_data_element_handler\n                     )\n                 ds.add(elem)\n         return ds\n",
    "model_name_or_path": "claude-3.7"
  },
  "pytest-dev__pytest-6116__claude-3.7": {
    "model_patch": "diff --git a/src/_pytest/main.py b/src/_pytest/main.py\nindex 843c5b5f7..b4261c188 100644\n--- a/src/_pytest/main.py\n+++ b/src/_pytest/main.py\n@@ -109,6 +109,7 @@ def pytest_addoption(parser):\n     group.addoption(\n         \"--collectonly\",\n         \"--collect-only\",\n+        \"--co\",\n         action=\"store_true\",\n         help=\"only collect tests, don't execute them.\",\n     ),\n",
    "model_name_or_path": "claude-3.7"
  },
  "pytest-dev__pytest-6116__deepseek-chat": {
    "model_patch": "diff --git a/src/_pytest/main.py b/src/_pytest/main.py\nindex 843c5b5f7..78c580395 100644\n--- a/src/_pytest/main.py\n+++ b/src/_pytest/main.py\n@@ -107,6 +107,7 @@ def pytest_addoption(parser):\n \n     group = parser.getgroup(\"collect\", \"collection\")\n     group.addoption(\n+        \"-C\",\n         \"--collectonly\",\n         \"--collect-only\",\n         action=\"store_true\",\n",
    "model_name_or_path": "deepseek-chat"
  },
  "django__django-14787__deepseek-chat": {
    "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..b79970671b 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -38,6 +38,9 @@ def _multi_decorate(decorators, method):\n         # 'func'. Also, wrap method.__get__() in a function because new\n         # attributes can't be set on bound method objects, only on functions.\n         bound_method = partial(method.__get__(self, type(self)))\n+        # Copy attributes from the original method to the partial object\n+        # so that decorators can access them (e.g., __name__, __module__)\n+        update_wrapper(bound_method, method)\n         for dec in decorators:\n             bound_method = dec(bound_method)\n         return bound_method(*args, **kwargs)\ndiff --git a/tests/decorators/tests.py b/tests/decorators/tests.py\nindex 46b01c1852..e496e2c790 100644\n--- a/tests/decorators/tests.py\n+++ b/tests/decorators/tests.py\n@@ -425,6 +425,29 @@ class MethodDecoratorTests(SimpleTestCase):\n                 def __module__(cls):\n                     return \"tests\"\n \n+    def test_wrapper_assignments(self):\n+        \"\"\"@method_decorator preserves wrapper assignments.\"\"\"\n+        func_name = None\n+        func_module = None\n+\n+        def decorator(func):\n+            @wraps(func)\n+            def inner(*args, **kwargs):\n+                nonlocal func_name, func_module\n+                func_name = getattr(func, '__name__', None)\n+                func_module = getattr(func, '__module__', None)\n+                return func(*args, **kwargs)\n+            return inner\n+\n+        class Test:\n+            @method_decorator(decorator)\n+            def method(self):\n+                return 'tests'\n+\n+        Test().method()\n+        self.assertEqual(func_name, 'method')\n+        self.assertIsNotNone(func_module)\n+\n \n class XFrameOptionsDecoratorsTests(TestCase):\n     \"\"\"\n",
    "model_name_or_path": "deepseek-chat"
  },
  "django__django-14787__claude-3.7": {
    "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..766eb98ea0 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -38,6 +38,8 @@ def _multi_decorate(decorators, method):\n         # 'func'. Also, wrap method.__get__() in a function because new\n         # attributes can't be set on bound method objects, only on functions.\n         bound_method = partial(method.__get__(self, type(self)))\n+        # Copy attributes from the original method to the partial object\n+        update_wrapper(bound_method, method)\n         for dec in decorators:\n             bound_method = dec(bound_method)\n         return bound_method(*args, **kwargs)\n",
    "model_name_or_path": "claude-3.7"
  },
  "django__django-14915__deepseek-chat": {
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5dcf923c12..bc7e6959e7 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1171,6 +1171,9 @@ class ModelChoiceIteratorValue:\n             other = other.value\n         return self.value == other\n \n+    def __hash__(self):\n+        return hash(self.value)\n+\n \n class ModelChoiceIterator:\n     def __init__(self, field):\n",
    "model_name_or_path": "deepseek-chat"
  },
  "django__django-14915__claude-3.7": {
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5dcf923c12..0ccc714afc 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1170,6 +1170,9 @@ class ModelChoiceIteratorValue:\n         if isinstance(other, ModelChoiceIteratorValue):\n             other = other.value\n         return self.value == other\n+        \n+    def __hash__(self):\n+        return hash(self.value)\n \n \n class ModelChoiceIterator:\n",
    "model_name_or_path": "claude-3.7"
  },
  "pytest-dev__pytest-7220__deepseek-chat": {
    "model_patch": "diff --git a/src/_pytest/_code/code.py b/src/_pytest/_code/code.py\nindex 7b17d7612..3040aa7f7 100644\n--- a/src/_pytest/_code/code.py\n+++ b/src/_pytest/_code/code.py\n@@ -789,14 +789,9 @@ class FormattedExcinfo:\n             return ReprEntry(lines, None, None, None, style)\n \n     def _makepath(self, path):\n-        if not self.abspath:\n-            try:\n-                np = py.path.local().bestrelpath(path)\n-            except OSError:\n-                return path\n-            if len(np) < len(str(path)):\n-                path = np\n-        return path\n+        if isinstance(path, str):\n+            return path\n+        return str(path)\n \n     def repr_traceback(self, excinfo: ExceptionInfo) -> \"ReprTraceback\":\n         traceback = excinfo.traceback\n",
    "model_name_or_path": "deepseek-chat"
  },
  "pytest-dev__pytest-7220__claude-3.7": {
    "model_patch": "diff --git a/src/_pytest/main.py b/src/_pytest/main.py\nindex de7e16744..72edb6f32 100644\n--- a/src/_pytest/main.py\n+++ b/src/_pytest/main.py\n@@ -421,6 +421,14 @@ class Session(nodes.FSCollector):\n \n     def _node_location_to_relpath(self, node_path: py.path.local) -> str:\n         # bestrelpath is a quite slow function\n+        try:\n+            # Check if the current working directory has changed from the original directory\n+            if os.getcwd() != str(self.startdir):\n+                # Use absolute path if cwd has changed\n+                return str(node_path)\n+        except OSError:\n+            # If os.getcwd() fails, use absolute path\n+            return str(node_path)\n         return self._bestrelpathcache[node_path]\n \n     @hookimpl(tryfirst=True)\n",
    "model_name_or_path": "claude-3.7"
  },
  "django__django-15902__deepseek-chat": {
    "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 3adbc6979a..7b63308d3f 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -31,6 +31,7 @@ class ManagementForm(Form):\n     new forms via JavaScript, you should increment the count field of this form\n     as well.\n     \"\"\"\n+    template_name_div = \"django/forms/formsets/div.html\"\n \n     TOTAL_FORMS = IntegerField(widget=HiddenInput)\n     INITIAL_FORMS = IntegerField(widget=HiddenInput)\n",
    "model_name_or_path": "deepseek-chat"
  },
  "django__django-15902__claude-3.7": {
    "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 3adbc6979a..bb90a669f6 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -40,6 +40,8 @@ class ManagementForm(Form):\n     MIN_NUM_FORMS = IntegerField(required=False, widget=HiddenInput)\n     MAX_NUM_FORMS = IntegerField(required=False, widget=HiddenInput)\n \n+    template_name = \"django/forms/div.html\"\n+\n     def clean(self):\n         cleaned_data = super().clean()\n         # When the management form is invalid, we don't know how many forms\n",
    "model_name_or_path": "claude-3.7"
  },
  "django__django-13925__deepseek-chat": {
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 4038859cfa..9e69f1b480 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1297,6 +1297,10 @@ class Model(metaclass=ModelBase):\n \n     @classmethod\n     def _check_default_pk(cls):\n+        # Skip the warning if the model inherits a primary key\n+        if cls._meta.parents and any(parent._meta.pk for parent in cls._meta.parents.values()):\n+            return []\n+            \n         if (\n             cls._meta.pk.auto_created and\n             not settings.is_overridden('DEFAULT_AUTO_FIELD') and\n",
    "model_name_or_path": "deepseek-chat"
  },
  "django__django-13925__claude-3.7": {
    "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 4038859cfa..0f03705de7 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1297,10 +1297,17 @@ class Model(metaclass=ModelBase):\n \n     @classmethod\n     def _check_default_pk(cls):\n+        # N\u00e3o emitir aviso para modelos que herdam a chave prim\u00e1ria de um modelo pai\n         if (\n             cls._meta.pk.auto_created and\n             not settings.is_overridden('DEFAULT_AUTO_FIELD') and\n-            not cls._meta.app_config._is_default_auto_field_overridden\n+            not cls._meta.app_config._is_default_auto_field_overridden and\n+            # Verificar se este \u00e9 um modelo filho que herda a chave prim\u00e1ria\n+            not (cls._meta.parents and any(\n+                parent._meta.pk is cls._meta.pk or\n+                parent._meta.pk.primary_key is True\n+                for parent in cls._meta.parents\n+            ))\n         ):\n             return [\n                 checks.Warning(\n",
    "model_name_or_path": "claude-3.7"
  },
  "sympy__sympy-24102__deepseek-chat": {
    "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 7ea14ce33a..8e320abce6 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -1067,6 +1067,9 @@ def recurse(expr):\n                     head = self._node_conversions.get(expr[0], Function(expr[0]))\n                 return head(*list(recurse(arg) for arg in expr[1:]))\n             else:\n+                # Handle Unicode characters (like Greek letters) properly\n+                if isinstance(expr, str) and not expr.isascii():\n+                    return symbols(expr)\n                 return self._atom_conversions.get(expr, sympify(expr))\n \n         return recurse(full_form_list)\n",
    "model_name_or_path": "deepseek-chat"
  },
  "sympy__sympy-24102__claude-3.7": {
    "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 7ea14ce33a..47f5dda1e6 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -586,7 +586,7 @@ def parse(self, s):\n         \"##\": lambda: [\"SlotSequence\", \"1\"],\n     }\n \n-    _literal = r\"[A-Za-z][A-Za-z0-9]*\"\n+    _literal = r\"[A-Za-z\\u0370-\\u03FF\\u1F00-\\u1FFF][A-Za-z0-9\\u0370-\\u03FF\\u1F00-\\u1FFF]*\"\n     _number = r\"(?:[0-9]+(?:\\.[0-9]*)?|\\.[0-9]+)\"\n \n     _enclosure_open = [\"(\", \"[\", \"[[\", \"{\"]\n",
    "model_name_or_path": "claude-3.7"
  },
  "pydicom__pydicom-1694__deepseek-chat": {
    "model_patch": "diff --git a/pydicom/dataset.py b/pydicom/dataset.py\nindex e32315011..f5b9c8430 100644\n--- a/pydicom/dataset.py\n+++ b/pydicom/dataset.py\n@@ -2492,9 +2492,9 @@ class Dataset:\n         json_dataset = {}\n         for key in self.keys():\n             json_key = '{:08X}'.format(key)\n-            data_element = self[key]\n             try:\n-                json_dataset[json_key] = data_element.to_json_dict(\n+                data_element = self[key]\n+                json_dataset[jjson_key] = data_element.to_json_dict(\n                     bulk_data_element_handler=bulk_data_element_handler,\n                     bulk_data_threshold=bulk_data_threshold\n                 )\n",
    "model_name_or_path": "deepseek-chat"
  },
  "pydicom__pydicom-1694__claude-3.7": {
    "model_patch": "diff --git a/pydicom/dataset.py b/pydicom/dataset.py\nindex e32315011..a6f887966 100644\n--- a/pydicom/dataset.py\n+++ b/pydicom/dataset.py\n@@ -2492,8 +2492,8 @@ class Dataset:\n         json_dataset = {}\n         for key in self.keys():\n             json_key = '{:08X}'.format(key)\n-            data_element = self[key]\n             try:\n+                data_element = self[key]\n                 json_dataset[json_key] = data_element.to_json_dict(\n                     bulk_data_element_handler=bulk_data_element_handler,\n                     bulk_data_threshold=bulk_data_threshold\n",
    "model_name_or_path": "claude-3.7"
  },
  "sqlfluff__sqlfluff-1625__deepseek-chat": {
    "model_patch": "diff --git a/src/sqlfluff/rules/L031.py b/src/sqlfluff/rules/L031.py\nindex 838c6ce5d..3ee45dca3 100644\n--- a/src/sqlfluff/rules/L031.py\n+++ b/src/sqlfluff/rules/L031.py\n@@ -152,6 +152,11 @@ class Rule_L031(BaseRule):\n         \"\"\"Lint and fix all aliases in joins - except for self-joins.\"\"\"\n         # A buffer to keep any violations.\n         violation_buff = []\n+        \n+        # Get all segments from from_clause onwards\n+        from_clause_segment = segment.get_child(\"from_clause\")\n+        from_clause_index = segment.segments.index(from_clause_segment)\n+        from_clause_and_after = segment.segments[from_clause_index:]\n \n         to_check = list(\n             self._filter_table_expressions(base_table, from_expression_elements)\n@@ -189,31 +194,39 @@ class Rule_L031(BaseRule):\n                 if used_alias_ref and used_alias_ref.raw == alias_name:\n                     ids_refs.append(used_alias_ref)\n \n-            # Find all references to alias in column references\n-            for exp_ref in column_reference_segments:\n-                used_alias_ref = exp_ref.get_child(\"identifier\")\n-                # exp_ref.get_child('dot') ensures that the column reference includes a table reference\n-                if used_alias_ref.raw == alias_name and exp_ref.get_child(\"dot\"):\n-                    ids_refs.append(used_alias_ref)\n+            # Check if there's a join clause\n+            has_join = any(\n+                clause.get_child(\"join_clause\")\n+                for clause in from_clause_and_after\n+            )\n \n-            # Fixes for deleting ` as sth` and for editing references to aliased tables\n-            fixes = [\n-                *[\n-                    LintFix(\"delete\", d)\n-                    for d in [alias_info.alias_exp_ref, alias_info.whitespace_ref]\n-                ],\n-                *[\n-                    LintFix(\"edit\", alias, alias.edit(alias_info.table_ref.raw))\n-                    for alias in [alias_info.alias_identifier_ref, *ids_refs]\n-                ],\n-            ]\n-\n-            violation_buff.append(\n-                LintResult(\n-                    anchor=alias_info.alias_identifier_ref,\n-                    description=\"Avoid using aliases in join condition\",\n-                    fixes=fixes,\n+            # Only report violations if there's a join clause\n+            if has_join:\n+                # Find all references to alias in column references\n+                for exp_ref in column_reference_segments:\n+                    used_alias_ref = exp_ref.get_child(\"identifier\")\n+                    # exp_ref.get_child('dot') ensures that the column reference includes a table reference\n+                    if used_alias_ref.raw == alias_name and exp_ref.get_child(\"dot\"):\n+                        ids_refs.append(used_alias_ref)\n+\n+                # Fixes for deleting ` as sth` and for editing references to aliased tables\n+                fixes = [\n+                    *[\n+                        LintFix(\"delete\", d)\n+                        for d in [alias_info.alias_exp_ref, alias_info.whitespace_ref]\n+                    ],\n+                    *[\n+                        LintFix(\"edit\", alias, alias.edit(alias_info.table_ref.raw))\n+                        for alias in [alias_info.alias_identifier_ref, *ids_refs]\n+                    ],\n+                ]\n+\n+                violation_buff.append(\n+                    LintResult(\n+                        anchor=alias_info.alias_identifier_ref,\n+                        description=\"Avoid using aliases in join condition\",\n+                        fixes=fixes,\n+                    )\n                 )\n-            )\n \n         return violation_buff or None\n",
    "model_name_or_path": "deepseek-chat"
  },
  "sqlfluff__sqlfluff-1625__claude-3.7": {
    "model_patch": "diff --git a/src/sqlfluff/rules/L031.py b/src/sqlfluff/rules/L031.py\nindex 838c6ce5d..0b30adcc9 100644\n--- a/src/sqlfluff/rules/L031.py\n+++ b/src/sqlfluff/rules/L031.py\n@@ -10,7 +10,7 @@ from sqlfluff.core.rules.doc_decorators import document_fix_compatible\n \n @document_fix_compatible\n class Rule_L031(BaseRule):\n-    \"\"\"Avoid table aliases in from clauses and join conditions.\n+    \"\"\"Avoid aliases in from clauses and join conditions.\n \n     | **Anti-pattern**\n     | In this example, alias 'o' is used for the orders table, and 'c' is used for 'customers' table.\n@@ -152,6 +152,11 @@ class Rule_L031(BaseRule):\n         \"\"\"Lint and fix all aliases in joins - except for self-joins.\"\"\"\n         # A buffer to keep any violations.\n         violation_buff = []\n+        \n+        # Get all segments from from_clause onwards\n+        from_clause_segment = segment.get_child(\"from_clause\")\n+        from_clause_index = segment.segments.index(from_clause_segment)\n+        from_clause_and_after = segment.segments[from_clause_index:]\n \n         to_check = list(\n             self._filter_table_expressions(base_table, from_expression_elements)\n@@ -193,9 +198,15 @@ class Rule_L031(BaseRule):\n             for exp_ref in column_reference_segments:\n                 used_alias_ref = exp_ref.get_child(\"identifier\")\n                 # exp_ref.get_child('dot') ensures that the column reference includes a table reference\n-                if used_alias_ref.raw == alias_name and exp_ref.get_child(\"dot\"):\n+                if used_alias_ref and used_alias_ref.raw == alias_name and exp_ref.get_child(\"dot\"):\n                     ids_refs.append(used_alias_ref)\n \n+            # Check if there's a join clause\n+            has_join = any(\n+                clause.get_child(\"join_clause\")\n+                for clause in from_clause_and_after\n+            )\n+\n             # Fixes for deleting ` as sth` and for editing references to aliased tables\n             fixes = [\n                 *[\n@@ -208,12 +219,14 @@ class Rule_L031(BaseRule):\n                 ],\n             ]\n \n-            violation_buff.append(\n-                LintResult(\n-                    anchor=alias_info.alias_identifier_ref,\n-                    description=\"Avoid using aliases in join condition\",\n-                    fixes=fixes,\n+            # Only report violations if there's a join clause\n+            if has_join:\n+                violation_buff.append(\n+                    LintResult(\n+                        anchor=alias_info.alias_identifier_ref,\n+                        description=\"Avoid aliases in from clauses and join conditions.\",\n+                        fixes=fixes,\n+                    )\n                 )\n-            )\n \n         return violation_buff or None\n",
    "model_name_or_path": "claude-3.7"
  },
  "pylint-dev__pylint-7114__deepseek-chat": {
    "model_patch": "diff --git a/pylint/checkers/imports.py b/pylint/checkers/imports.py\nindex 7cab78586..155c7dbc7 100644\n--- a/pylint/checkers/imports.py\n+++ b/pylint/checkers/imports.py\n@@ -795,6 +795,16 @@ class ImportsChecker(DeprecatedMixin, BaseChecker):\n         self, importnode: ImportNode, modname: str | None\n     ) -> nodes.Module | None:\n         try:\n+            # Special handling for modules with same name as directory\n+            if modname and '.' in modname:\n+                parts = modname.split('.')\n+                if len(parts) >= 2 and parts[-1] == parts[-2]:\n+                    try:\n+                        return importnode.do_import_module(modname)\n+                    except astroid.AstroidBuildingError:\n+                        # Try without the last part (treat directory/__init__.py case)\n+                        return importnode.do_import_module('.'.join(parts[:-1]))\n+            \n             return importnode.do_import_module(modname)\n         except astroid.TooManyLevelsError:\n             if _ignore_import_failure(importnode, modname, self._ignored_modules):\n",
    "model_name_or_path": "deepseek-chat"
  },
  "pylint-dev__pylint-7114__claude-3.7": {
    "model_patch": "diff --git a/pylint/checkers/imports.py b/pylint/checkers/imports.py\nindex 7cab78586..159424b95 100644\n--- a/pylint/checkers/imports.py\n+++ b/pylint/checkers/imports.py\n@@ -286,739 +286,4 @@ MSGS: dict[str, MessageDefinitionTuple] = {\n         \"Used when code and imports are mixed.\",\n     ),\n     \"C0414\": (\n-        \"Import alias does not rename original package\",\n-        \"useless-import-alias\",\n-        \"Used when an import alias is same as original package, \"\n-        \"e.g., using import numpy as numpy instead of import numpy as np.\",\n-    ),\n-    \"C0415\": (\n-        \"Import outside toplevel (%s)\",\n-        \"import-outside-toplevel\",\n-        \"Used when an import statement is used anywhere other than the module \"\n-        \"toplevel. Move this import to the top of the file.\",\n-    ),\n-}\n-\n-\n-DEFAULT_STANDARD_LIBRARY = ()\n-DEFAULT_KNOWN_THIRD_PARTY = (\"enchant\",)\n-DEFAULT_PREFERRED_MODULES = ()\n-\n-\n-class ImportsChecker(DeprecatedMixin, BaseChecker):\n-    \"\"\"BaseChecker for import statements.\n-\n-    Checks for\n-    * external modules dependencies\n-    * relative / wildcard imports\n-    * cyclic imports\n-    * uses of deprecated modules\n-    * uses of modules instead of preferred modules\n-    \"\"\"\n-\n-    name = \"imports\"\n-    msgs = {**DeprecatedMixin.DEPRECATED_MODULE_MESSAGE, **MSGS}\n-    default_deprecated_modules = ()\n-\n-    options = (\n-        (\n-            \"deprecated-modules\",\n-            {\n-                \"default\": default_deprecated_modules,\n-                \"type\": \"csv\",\n-                \"metavar\": \"<modules>\",\n-                \"help\": \"Deprecated modules which should not be used,\"\n-                \" separated by a comma.\",\n-            },\n-        ),\n-        (\n-            \"preferred-modules\",\n-            {\n-                \"default\": DEFAULT_PREFERRED_MODULES,\n-                \"type\": \"csv\",\n-                \"metavar\": \"<module:preferred-module>\",\n-                \"help\": \"Couples of modules and preferred modules,\"\n-                \" separated by a comma.\",\n-            },\n-        ),\n-        (\n-            \"import-graph\",\n-            {\n-                \"default\": \"\",\n-                \"type\": \"path\",\n-                \"metavar\": \"<file.gv>\",\n-                \"help\": \"Output a graph (.gv or any supported image format) of\"\n-                \" all (i.e. internal and external) dependencies to the given file\"\n-                \" (report RP0402 must not be disabled).\",\n-            },\n-        ),\n-        (\n-            \"ext-import-graph\",\n-            {\n-                \"default\": \"\",\n-                \"type\": \"path\",\n-                \"metavar\": \"<file.gv>\",\n-                \"help\": \"Output a graph (.gv or any supported image format)\"\n-                \" of external dependencies to the given file\"\n-                \" (report RP0402 must not be disabled).\",\n-            },\n-        ),\n-        (\n-            \"int-import-graph\",\n-            {\n-                \"default\": \"\",\n-                \"type\": \"path\",\n-                \"metavar\": \"<file.gv>\",\n-                \"help\": \"Output a graph (.gv or any supported image format)\"\n-                \" of internal dependencies to the given file\"\n-                \" (report RP0402 must not be disabled).\",\n-            },\n-        ),\n-        (\n-            \"known-standard-library\",\n-            {\n-                \"default\": DEFAULT_STANDARD_LIBRARY,\n-                \"type\": \"csv\",\n-                \"metavar\": \"<modules>\",\n-                \"help\": \"Force import order to recognize a module as part of \"\n-                \"the standard compatibility libraries.\",\n-            },\n-        ),\n-        (\n-            \"known-third-party\",\n-            {\n-                \"default\": DEFAULT_KNOWN_THIRD_PARTY,\n-                \"type\": \"csv\",\n-                \"metavar\": \"<modules>\",\n-                \"help\": \"Force import order to recognize a module as part of \"\n-                \"a third party library.\",\n-            },\n-        ),\n-        (\n-            \"allow-any-import-level\",\n-            {\n-                \"default\": (),\n-                \"type\": \"csv\",\n-                \"metavar\": \"<modules>\",\n-                \"help\": (\n-                    \"List of modules that can be imported at any level, not just \"\n-                    \"the top level one.\"\n-                ),\n-            },\n-        ),\n-        (\n-            \"allow-wildcard-with-all\",\n-            {\n-                \"default\": False,\n-                \"type\": \"yn\",\n-                \"metavar\": \"<y or n>\",\n-                \"help\": \"Allow wildcard imports from modules that define __all__.\",\n-            },\n-        ),\n-    )\n-\n-    def __init__(self, linter: PyLinter) -> None:\n-        BaseChecker.__init__(self, linter)\n-        self.import_graph: defaultdict[str, set[str]] = defaultdict(set)\n-        self._imports_stack: list[tuple[Any, Any]] = []\n-        self._first_non_import_node = None\n-        self._module_pkg: dict[\n-            Any, Any\n-        ] = {}  # mapping of modules to the pkg they belong in\n-        self._allow_any_import_level: set[Any] = set()\n-        self.reports = (\n-            (\"RP0401\", \"External dependencies\", self._report_external_dependencies),\n-            (\"RP0402\", \"Modules dependencies graph\", self._report_dependencies_graph),\n-        )\n-\n-    def open(self) -> None:\n-        \"\"\"Called before visiting project (i.e set of modules).\"\"\"\n-        self.linter.stats.dependencies = {}\n-        self.linter.stats = self.linter.stats\n-        self.import_graph = defaultdict(set)\n-        self._module_pkg = {}  # mapping of modules to the pkg they belong in\n-        self._excluded_edges: defaultdict[str, set[str]] = defaultdict(set)\n-        self._ignored_modules: Sequence[str] = self.linter.config.ignored_modules\n-        # Build a mapping {'module': 'preferred-module'}\n-        self.preferred_modules = dict(\n-            module.split(\":\")\n-            for module in self.linter.config.preferred_modules\n-            if \":\" in module\n-        )\n-        self._allow_any_import_level = set(self.linter.config.allow_any_import_level)\n-\n-    def _import_graph_without_ignored_edges(self) -> defaultdict[str, set[str]]:\n-        filtered_graph = copy.deepcopy(self.import_graph)\n-        for node in filtered_graph:\n-            filtered_graph[node].difference_update(self._excluded_edges[node])\n-        return filtered_graph\n-\n-    def close(self) -> None:\n-        \"\"\"Called before visiting project (i.e set of modules).\"\"\"\n-        if self.linter.is_message_enabled(\"cyclic-import\"):\n-            graph = self._import_graph_without_ignored_edges()\n-            vertices = list(graph)\n-            for cycle in get_cycles(graph, vertices=vertices):\n-                self.add_message(\"cyclic-import\", args=\" -> \".join(cycle))\n-\n-    def deprecated_modules(self) -> set[str]:\n-        \"\"\"Callback returning the deprecated modules.\"\"\"\n-        # First get the modules the user indicated\n-        all_deprecated_modules = set(self.linter.config.deprecated_modules)\n-        # Now get the hard-coded ones from the stdlib\n-        for since_vers, mod_set in DEPRECATED_MODULES.items():\n-            if since_vers <= sys.version_info:\n-                all_deprecated_modules = all_deprecated_modules.union(mod_set)\n-        return all_deprecated_modules\n-\n-    def visit_import(self, node: nodes.Import) -> None:\n-        \"\"\"Triggered when an import statement is seen.\"\"\"\n-        self._check_reimport(node)\n-        self._check_import_as_rename(node)\n-        self._check_toplevel(node)\n-\n-        names = [name for name, _ in node.names]\n-        if len(names) >= 2:\n-            self.add_message(\"multiple-imports\", args=\", \".join(names), node=node)\n-\n-        for name in names:\n-            self.check_deprecated_module(node, name)\n-            self._check_preferred_module(node, name)\n-            imported_module = self._get_imported_module(node, name)\n-            if isinstance(node.parent, nodes.Module):\n-                # Allow imports nested\n-                self._check_position(node)\n-            if isinstance(node.scope(), nodes.Module):\n-                self._record_import(node, imported_module)\n-\n-            if imported_module is None:\n-                continue\n-\n-            self._add_imported_module(node, imported_module.name)\n-\n-    def visit_importfrom(self, node: nodes.ImportFrom) -> None:\n-        \"\"\"Triggered when a from statement is seen.\"\"\"\n-        basename = node.modname\n-        imported_module = self._get_imported_module(node, basename)\n-        absolute_name = get_import_name(node, basename)\n-\n-        self._check_import_as_rename(node)\n-        self._check_misplaced_future(node)\n-        self.check_deprecated_module(node, absolute_name)\n-        self._check_preferred_module(node, basename)\n-        self._check_wildcard_imports(node, imported_module)\n-        self._check_same_line_imports(node)\n-        self._check_reimport(node, basename=basename, level=node.level)\n-        self._check_toplevel(node)\n-\n-        if isinstance(node.parent, nodes.Module):\n-            # Allow imports nested\n-            self._check_position(node)\n-        if isinstance(node.scope(), nodes.Module):\n-            self._record_import(node, imported_module)\n-        if imported_module is None:\n-            return\n-        for name, _ in node.names:\n-            if name != \"*\":\n-                self._add_imported_module(node, f\"{imported_module.name}.{name}\")\n-            else:\n-                self._add_imported_module(node, imported_module.name)\n-\n-    def leave_module(self, node: nodes.Module) -> None:\n-        # Check imports are grouped by category (standard, 3rd party, local)\n-        std_imports, ext_imports, loc_imports = self._check_imports_order(node)\n-\n-        # Check that imports are grouped by package within a given category\n-        met_import: set[str] = set()  # set for 'import x' style\n-        met_from: set[str] = set()  # set for 'from x import y' style\n-        current_package = None\n-        for import_node, import_name in std_imports + ext_imports + loc_imports:\n-            met = met_from if isinstance(import_node, nodes.ImportFrom) else met_import\n-            package, _, _ = import_name.partition(\".\")\n-            if (\n-                current_package\n-                and current_package != package\n-                and package in met\n-                and is_node_in_guarded_import_block(import_node) is False\n-            ):\n-                self.add_message(\"ungrouped-imports\", node=import_node, args=package)\n-            current_package = package\n-            if not self.linter.is_message_enabled(\n-                \"ungrouped-imports\", import_node.fromlineno\n-            ):\n-                continue\n-            met.add(package)\n-\n-        self._imports_stack = []\n-        self._first_non_import_node = None\n-\n-    def compute_first_non_import_node(\n-        self,\n-        node: nodes.If\n-        | nodes.Expr\n-        | nodes.Comprehension\n-        | nodes.IfExp\n-        | nodes.Assign\n-        | nodes.AssignAttr\n-        | nodes.TryExcept\n-        | nodes.TryFinally,\n-    ) -> None:\n-        # if the node does not contain an import instruction, and if it is the\n-        # first node of the module, keep a track of it (all the import positions\n-        # of the module will be compared to the position of this first\n-        # instruction)\n-        if self._first_non_import_node:\n-            return\n-        if not isinstance(node.parent, nodes.Module):\n-            return\n-        nested_allowed = [nodes.TryExcept, nodes.TryFinally]\n-        is_nested_allowed = [\n-            allowed for allowed in nested_allowed if isinstance(node, allowed)\n-        ]\n-        if is_nested_allowed and any(\n-            node.nodes_of_class((nodes.Import, nodes.ImportFrom))\n-        ):\n-            return\n-        if isinstance(node, nodes.Assign):\n-            # Add compatibility for module level dunder names\n-            # https://www.python.org/dev/peps/pep-0008/#module-level-dunder-names\n-            valid_targets = [\n-                isinstance(target, nodes.AssignName)\n-                and target.name.startswith(\"__\")\n-                and target.name.endswith(\"__\")\n-                for target in node.targets\n-            ]\n-            if all(valid_targets):\n-                return\n-        self._first_non_import_node = node\n-\n-    visit_tryfinally = (\n-        visit_tryexcept\n-    ) = (\n-        visit_assignattr\n-    ) = (\n-        visit_assign\n-    ) = (\n-        visit_ifexp\n-    ) = visit_comprehension = visit_expr = visit_if = compute_first_non_import_node\n-\n-    def visit_functiondef(\n-        self, node: nodes.FunctionDef | nodes.While | nodes.For | nodes.ClassDef\n-    ) -> None:\n-        # If it is the first non import instruction of the module, record it.\n-        if self._first_non_import_node:\n-            return\n-\n-        # Check if the node belongs to an `If` or a `Try` block. If they\n-        # contain imports, skip recording this node.\n-        if not isinstance(node.parent.scope(), nodes.Module):\n-            return\n-\n-        root = node\n-        while not isinstance(root.parent, nodes.Module):\n-            root = root.parent\n-\n-        if isinstance(root, (nodes.If, nodes.TryFinally, nodes.TryExcept)):\n-            if any(root.nodes_of_class((nodes.Import, nodes.ImportFrom))):\n-                return\n-\n-        self._first_non_import_node = node\n-\n-    visit_classdef = visit_for = visit_while = visit_functiondef\n-\n-    def _check_misplaced_future(self, node: nodes.ImportFrom) -> None:\n-        basename = node.modname\n-        if basename == \"__future__\":\n-            # check if this is the first non-docstring statement in the module\n-            prev = node.previous_sibling()\n-            if prev:\n-                # consecutive future statements are possible\n-                if not (\n-                    isinstance(prev, nodes.ImportFrom) and prev.modname == \"__future__\"\n-                ):\n-                    self.add_message(\"misplaced-future\", node=node)\n-            return\n-\n-    def _check_same_line_imports(self, node: nodes.ImportFrom) -> None:\n-        # Detect duplicate imports on the same line.\n-        names = (name for name, _ in node.names)\n-        counter = collections.Counter(names)\n-        for name, count in counter.items():\n-            if count > 1:\n-                self.add_message(\"reimported\", node=node, args=(name, node.fromlineno))\n-\n-    def _check_position(self, node: ImportNode) -> None:\n-        \"\"\"Check `node` import or importfrom node position is correct.\n-\n-        Send a message  if `node` comes before another instruction\n-        \"\"\"\n-        # if a first non-import instruction has already been encountered,\n-        # it means the import comes after it and therefore is not well placed\n-        if self._first_non_import_node:\n-            if self.linter.is_message_enabled(\n-                \"wrong-import-position\", self._first_non_import_node.fromlineno\n-            ):\n-                self.add_message(\n-                    \"wrong-import-position\", node=node, args=node.as_string()\n-                )\n-            else:\n-                self.linter.add_ignored_message(\n-                    \"wrong-import-position\", node.fromlineno, node\n-                )\n-\n-    def _record_import(\n-        self,\n-        node: ImportNode,\n-        importedmodnode: nodes.Module | None,\n-    ) -> None:\n-        \"\"\"Record the package `node` imports from.\"\"\"\n-        if isinstance(node, nodes.ImportFrom):\n-            importedname = node.modname\n-        else:\n-            importedname = importedmodnode.name if importedmodnode else None\n-        if not importedname:\n-            importedname = node.names[0][0].split(\".\")[0]\n-\n-        if isinstance(node, nodes.ImportFrom) and (node.level or 0) >= 1:\n-            # We need the importedname with first point to detect local package\n-            # Example of node:\n-            #  'from .my_package1 import MyClass1'\n-            #  the output should be '.my_package1' instead of 'my_package1'\n-            # Example of node:\n-            #  'from . import my_package2'\n-            #  the output should be '.my_package2' instead of '{pyfile}'\n-            importedname = \".\" + importedname\n-\n-        self._imports_stack.append((node, importedname))\n-\n-    @staticmethod\n-    def _is_fallback_import(node, imports):\n-        imports = [import_node for (import_node, _) in imports]\n-        return any(astroid.are_exclusive(import_node, node) for import_node in imports)\n-\n-    def _check_imports_order(self, _module_node):\n-        \"\"\"Checks imports of module `node` are grouped by category.\n-\n-        Imports must follow this order: standard, 3rd party, local\n-        \"\"\"\n-        std_imports = []\n-        third_party_imports = []\n-        first_party_imports = []\n-        # need of a list that holds third or first party ordered import\n-        external_imports = []\n-        local_imports = []\n-        third_party_not_ignored = []\n-        first_party_not_ignored = []\n-        local_not_ignored = []\n-        isort_driver = IsortDriver(self.linter.config)\n-        for node, modname in self._imports_stack:\n-            if modname.startswith(\".\"):\n-                package = \".\" + modname.split(\".\")[1]\n-            else:\n-                package = modname.split(\".\")[0]\n-            nested = not isinstance(node.parent, nodes.Module)\n-            ignore_for_import_order = not self.linter.is_message_enabled(\n-                \"wrong-import-order\", node.fromlineno\n-            )\n-            import_category = isort_driver.place_module(package)\n-            node_and_package_import = (node, package)\n-            if import_category in {\"FUTURE\", \"STDLIB\"}:\n-                std_imports.append(node_and_package_import)\n-                wrong_import = (\n-                    third_party_not_ignored\n-                    or first_party_not_ignored\n-                    or local_not_ignored\n-                )\n-                if self._is_fallback_import(node, wrong_import):\n-                    continue\n-                if wrong_import and not nested:\n-                    self.add_message(\n-                        \"wrong-import-order\",\n-                        node=node,\n-                        args=(\n-                            f'standard import \"{node.as_string()}\"',\n-                            f'\"{wrong_import[0][0].as_string()}\"',\n-                        ),\n-                    )\n-            elif import_category == \"THIRDPARTY\":\n-                third_party_imports.append(node_and_package_import)\n-                external_imports.append(node_and_package_import)\n-                if not nested:\n-                    if not ignore_for_import_order:\n-                        third_party_not_ignored.append(node_and_package_import)\n-                    else:\n-                        self.linter.add_ignored_message(\n-                            \"wrong-import-order\", node.fromlineno, node\n-                        )\n-                wrong_import = first_party_not_ignored or local_not_ignored\n-                if wrong_import and not nested:\n-                    self.add_message(\n-                        \"wrong-import-order\",\n-                        node=node,\n-                        args=(\n-                            f'third party import \"{node.as_string()}\"',\n-                            f'\"{wrong_import[0][0].as_string()}\"',\n-                        ),\n-                    )\n-            elif import_category == \"FIRSTPARTY\":\n-                first_party_imports.append(node_and_package_import)\n-                external_imports.append(node_and_package_import)\n-                if not nested:\n-                    if not ignore_for_import_order:\n-                        first_party_not_ignored.append(node_and_package_import)\n-                    else:\n-                        self.linter.add_ignored_message(\n-                            \"wrong-import-order\", node.fromlineno, node\n-                        )\n-                wrong_import = local_not_ignored\n-                if wrong_import and not nested:\n-                    self.add_message(\n-                        \"wrong-import-order\",\n-                        node=node,\n-                        args=(\n-                            f'first party import \"{node.as_string()}\"',\n-                            f'\"{wrong_import[0][0].as_string()}\"',\n-                        ),\n-                    )\n-            elif import_category == \"LOCALFOLDER\":\n-                local_imports.append((node, package))\n-                if not nested:\n-                    if not ignore_for_import_order:\n-                        local_not_ignored.append((node, package))\n-                    else:\n-                        self.linter.add_ignored_message(\n-                            \"wrong-import-order\", node.fromlineno, node\n-                        )\n-        return std_imports, external_imports, local_imports\n-\n-    def _get_imported_module(\n-        self, importnode: ImportNode, modname: str | None\n-    ) -> nodes.Module | None:\n-        try:\n-            return importnode.do_import_module(modname)\n-        except astroid.TooManyLevelsError:\n-            if _ignore_import_failure(importnode, modname, self._ignored_modules):\n-                return None\n-            self.add_message(\"relative-beyond-top-level\", node=importnode)\n-        except astroid.AstroidSyntaxError as exc:\n-            message = f\"Cannot import {modname!r} due to '{exc.error}'\"\n-            self.add_message(\n-                \"syntax-error\", line=importnode.lineno, args=message, confidence=HIGH\n-            )\n-\n-        except astroid.AstroidBuildingError:\n-            if not self.linter.is_message_enabled(\"import-error\"):\n-                return None\n-            if _ignore_import_failure(importnode, modname, self._ignored_modules):\n-                return None\n-            if (\n-                not self.linter.config.analyse_fallback_blocks\n-                and is_from_fallback_block(importnode)\n-            ):\n-                return None\n-\n-            dotted_modname = get_import_name(importnode, modname)\n-            self.add_message(\"import-error\", args=repr(dotted_modname), node=importnode)\n-        except Exception as e:  # pragma: no cover\n-            raise astroid.AstroidError from e\n-        return None\n-\n-    def _add_imported_module(self, node: ImportNode, importedmodname: str) -> None:\n-        \"\"\"Notify an imported module, used to analyze dependencies.\"\"\"\n-        module_file = node.root().file\n-        context_name = node.root().name\n-        base = os.path.splitext(os.path.basename(module_file))[0]\n-\n-        try:\n-            importedmodname = astroid.modutils.get_module_part(\n-                importedmodname, module_file\n-            )\n-        except ImportError:\n-            pass\n-\n-        in_type_checking_block = isinstance(node.parent, nodes.If) and is_typing_guard(\n-            node.parent\n-        )\n-\n-        if context_name == importedmodname:\n-            self.add_message(\"import-self\", node=node)\n-\n-        elif not astroid.modutils.is_standard_module(importedmodname):\n-            # if this is not a package __init__ module\n-            if base != \"__init__\" and context_name not in self._module_pkg:\n-                # record the module's parent, or the module itself if this is\n-                # a top level module, as the package it belongs to\n-                self._module_pkg[context_name] = context_name.rsplit(\".\", 1)[0]\n-\n-            # handle dependencies\n-            dependencies_stat: dict[str, set[str]] = self.linter.stats.dependencies\n-            importedmodnames = dependencies_stat.setdefault(importedmodname, set())\n-            if context_name not in importedmodnames:\n-                importedmodnames.add(context_name)\n-\n-            # update import graph\n-            self.import_graph[context_name].add(importedmodname)\n-            if (\n-                not self.linter.is_message_enabled(\"cyclic-import\", line=node.lineno)\n-                or in_type_checking_block\n-            ):\n-                self._excluded_edges[context_name].add(importedmodname)\n-\n-    def _check_preferred_module(self, node, mod_path):\n-        \"\"\"Check if the module has a preferred replacement.\"\"\"\n-        if mod_path in self.preferred_modules:\n-            self.add_message(\n-                \"preferred-module\",\n-                node=node,\n-                args=(self.preferred_modules[mod_path], mod_path),\n-            )\n-\n-    def _check_import_as_rename(self, node: ImportNode) -> None:\n-        names = node.names\n-        for name in names:\n-            if not all(name):\n-                return\n-\n-            splitted_packages = name[0].rsplit(\".\", maxsplit=1)\n-            import_name = splitted_packages[-1]\n-            aliased_name = name[1]\n-            if import_name != aliased_name:\n-                continue\n-\n-            if len(splitted_packages) == 1:\n-                self.add_message(\"useless-import-alias\", node=node)\n-            elif len(splitted_packages) == 2:\n-                self.add_message(\n-                    \"consider-using-from-import\",\n-                    node=node,\n-                    args=(splitted_packages[0], import_name),\n-                )\n-\n-    def _check_reimport(\n-        self,\n-        node: ImportNode,\n-        basename: str | None = None,\n-        level: int | None = None,\n-    ) -> None:\n-        \"\"\"Check if the import is necessary (i.e. not already done).\"\"\"\n-        if not self.linter.is_message_enabled(\"reimported\"):\n-            return\n-\n-        frame = node.frame(future=True)\n-        root = node.root()\n-        contexts = [(frame, level)]\n-        if root is not frame:\n-            contexts.append((root, None))\n-\n-        for known_context, known_level in contexts:\n-            for name, alias in node.names:\n-                first = _get_first_import(\n-                    node, known_context, name, basename, known_level, alias\n-                )\n-                if first is not None:\n-                    self.add_message(\n-                        \"reimported\", node=node, args=(name, first.fromlineno)\n-                    )\n-\n-    def _report_external_dependencies(\n-        self, sect: Section, _: LinterStats, _dummy: LinterStats | None\n-    ) -> None:\n-        \"\"\"Return a verbatim layout for displaying dependencies.\"\"\"\n-        dep_info = _make_tree_defs(self._external_dependencies_info().items())\n-        if not dep_info:\n-            raise EmptyReportError()\n-        tree_str = _repr_tree_defs(dep_info)\n-        sect.append(VerbatimText(tree_str))\n-\n-    def _report_dependencies_graph(\n-        self, sect: Section, _: LinterStats, _dummy: LinterStats | None\n-    ) -> None:\n-        \"\"\"Write dependencies as a dot (graphviz) file.\"\"\"\n-        dep_info = self.linter.stats.dependencies\n-        if not dep_info or not (\n-            self.linter.config.import_graph\n-            or self.linter.config.ext_import_graph\n-            or self.linter.config.int_import_graph\n-        ):\n-            raise EmptyReportError()\n-        filename = self.linter.config.import_graph\n-        if filename:\n-            _make_graph(filename, dep_info, sect, \"\")\n-        filename = self.linter.config.ext_import_graph\n-        if filename:\n-            _make_graph(filename, self._external_dependencies_info(), sect, \"external \")\n-        filename = self.linter.config.int_import_graph\n-        if filename:\n-            _make_graph(filename, self._internal_dependencies_info(), sect, \"internal \")\n-\n-    def _filter_dependencies_graph(self, internal: bool) -> defaultdict[str, set[str]]:\n-        \"\"\"Build the internal or the external dependency graph.\"\"\"\n-        graph: defaultdict[str, set[str]] = defaultdict(set)\n-        for importee, importers in self.linter.stats.dependencies.items():\n-            for importer in importers:\n-                package = self._module_pkg.get(importer, importer)\n-                is_inside = importee.startswith(package)\n-                if is_inside and internal or not is_inside and not internal:\n-                    graph[importee].add(importer)\n-        return graph\n-\n-    @astroid.decorators.cached\n-    def _external_dependencies_info(self) -> defaultdict[str, set[str]]:\n-        \"\"\"Return cached external dependencies information or build and\n-        cache them.\n-        \"\"\"\n-        return self._filter_dependencies_graph(internal=False)\n-\n-    @astroid.decorators.cached\n-    def _internal_dependencies_info(self) -> defaultdict[str, set[str]]:\n-        \"\"\"Return cached internal dependencies information or build and\n-        cache them.\n-        \"\"\"\n-        return self._filter_dependencies_graph(internal=True)\n-\n-    def _check_wildcard_imports(\n-        self, node: nodes.ImportFrom, imported_module: nodes.Module | None\n-    ) -> None:\n-        if node.root().package:\n-            # Skip the check if in __init__.py issue #2026\n-            return\n-\n-        wildcard_import_is_allowed = self._wildcard_import_is_allowed(imported_module)\n-        for name, _ in node.names:\n-            if name == \"*\" and not wildcard_import_is_allowed:\n-                self.add_message(\"wildcard-import\", args=node.modname, node=node)\n-\n-    def _wildcard_import_is_allowed(self, imported_module: nodes.Module | None) -> bool:\n-        return (\n-            self.linter.config.allow_wildcard_with_all\n-            and imported_module is not None\n-            and \"__all__\" in imported_module.locals\n-        )\n-\n-    def _check_toplevel(self, node: ImportNode) -> None:\n-        \"\"\"Check whether the import is made outside the module toplevel.\"\"\"\n-        # If the scope of the import is a module, then obviously it is\n-        # not outside the module toplevel.\n-        if isinstance(node.scope(), nodes.Module):\n-            return\n-\n-        module_names = [\n-            f\"{node.modname}.{name[0]}\"\n-            if isinstance(node, nodes.ImportFrom)\n-            else name[0]\n-            for name in node.names\n-        ]\n-\n-        # Get the full names of all the imports that are only allowed at the module level\n-        scoped_imports = [\n-            name for name in module_names if name not in self._allow_any_import_level\n-        ]\n-\n-        if scoped_imports:\n-            self.add_message(\n-                \"import-outside-toplevel\", args=\", \".join(scoped_imports), node=node\n-            )\n-\n-\n-def register(linter: PyLinter) -> None:\n-    linter.register_checker(ImportsChecker(linter))\n+        \"Import alias does not rename\ndiff --git a/pylint/lint/expand_modules.py b/pylint/lint/expand_modules.py\nindex 289e1afce..0e0ddc8d2 100644\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -91,7 +91,16 @@ def expand_modules(\n             except ImportError:\n                 modname = os.path.splitext(basename)[0]\n             if os.path.isdir(something):\n-                filepath = os.path.join(something, \"__init__.py\")\n+                init_path = os.path.join(something, \"__init__.py\")\n+                if os.path.exists(init_path):\n+                    filepath = init_path\n+                else:\n+                    # Check if there's a module with the same name as the directory\n+                    same_name_module = os.path.join(something, basename + \".py\")\n+                    if os.path.exists(same_name_module):\n+                        filepath = same_name_module\n+                    else:\n+                        filepath = init_path  # Keep the original behavior as fallback\n             else:\n                 filepath = something\n         else:\n",
    "model_name_or_path": "claude-3.7"
  }
}